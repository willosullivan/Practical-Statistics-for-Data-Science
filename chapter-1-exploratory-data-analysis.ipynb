{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of Python as a builder. They have a mental skillset but often find themselves needing to complement that skillset with physical tools, for example to measure a sheet of concrete or to nail some nails into a frame. This is where **modules** come in. \n",
    "\n",
    "**Modules** are like a toolboxes that enable the data scientist the flexibility and power of calling pre-written code (methods) from pre-existing Classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default Jupyter will restrict our view our the entire width of the dataframe. I like to turn this off unless the dataframe is significant dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off max columns so we can view the entire dataframe width\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in our data to our assigned variables 'df'\n",
    "df = pd.read_csv('all_seasons.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having imported the necessery tools for our analysis and imported our data, let's take a high level look at out dataset.\n",
    "\n",
    "I have downloaded this dataset from Kaggle and I know that it's pretty useable already. However, most often our data won't be so readily useable, if we have for example scrapped it from a webpage or used an API call.\n",
    "\n",
    "Let's begin by visualising the dataset by calling the \".head()\" method on our dataframe variable \"df\". This is the third time we have called a Pandas method. The first time was when we turned off max columns with \"pd.set_option\" and the second time was when we read in our csv file into our notebook with \"pd.read_csv()\". \n",
    "\n",
    "If you notice at the top where we called in the modules/libraries/Classes, we assigned an alias to the Numpy and Pandas classes. This is to save us time when we call methods from each class from thereon out. Instead of having to write \"Pandas.set_option()\" or \"Numpy.mean()\", we can use the Class aliases \"pd.set_option()\" and \"np.mean()\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>player_name</th>\n",
       "      <th>team_abbreviation</th>\n",
       "      <th>age</th>\n",
       "      <th>player_height</th>\n",
       "      <th>player_weight</th>\n",
       "      <th>college</th>\n",
       "      <th>country</th>\n",
       "      <th>draft_year</th>\n",
       "      <th>draft_round</th>\n",
       "      <th>draft_number</th>\n",
       "      <th>gp</th>\n",
       "      <th>pts</th>\n",
       "      <th>reb</th>\n",
       "      <th>ast</th>\n",
       "      <th>net_rating</th>\n",
       "      <th>oreb_pct</th>\n",
       "      <th>dreb_pct</th>\n",
       "      <th>usg_pct</th>\n",
       "      <th>ts_pct</th>\n",
       "      <th>ast_pct</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Travis Knight</td>\n",
       "      <td>LAL</td>\n",
       "      <td>22.0</td>\n",
       "      <td>213.36</td>\n",
       "      <td>106.59412</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>USA</td>\n",
       "      <td>1996</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>71</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.052</td>\n",
       "      <td>1996-97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Matt Fish</td>\n",
       "      <td>MIA</td>\n",
       "      <td>27.0</td>\n",
       "      <td>210.82</td>\n",
       "      <td>106.59412</td>\n",
       "      <td>North Carolina-Wilmington</td>\n",
       "      <td>USA</td>\n",
       "      <td>1992</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.1</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1996-97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Matt Bullard</td>\n",
       "      <td>HOU</td>\n",
       "      <td>30.0</td>\n",
       "      <td>208.28</td>\n",
       "      <td>106.59412</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>USA</td>\n",
       "      <td>Undrafted</td>\n",
       "      <td>Undrafted</td>\n",
       "      <td>Undrafted</td>\n",
       "      <td>71</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.099</td>\n",
       "      <td>1996-97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Marty Conlon</td>\n",
       "      <td>BOS</td>\n",
       "      <td>29.0</td>\n",
       "      <td>210.82</td>\n",
       "      <td>111.13004</td>\n",
       "      <td>Providence</td>\n",
       "      <td>USA</td>\n",
       "      <td>Undrafted</td>\n",
       "      <td>Undrafted</td>\n",
       "      <td>Undrafted</td>\n",
       "      <td>74</td>\n",
       "      <td>7.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.101</td>\n",
       "      <td>1996-97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Martin Muursepp</td>\n",
       "      <td>DAL</td>\n",
       "      <td>22.0</td>\n",
       "      <td>205.74</td>\n",
       "      <td>106.59412</td>\n",
       "      <td>None</td>\n",
       "      <td>USA</td>\n",
       "      <td>1996</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>42</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-14.5</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.114</td>\n",
       "      <td>1996-97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      player_name team_abbreviation   age  player_height  \\\n",
       "0           0    Travis Knight               LAL  22.0         213.36   \n",
       "1           1        Matt Fish               MIA  27.0         210.82   \n",
       "2           2     Matt Bullard               HOU  30.0         208.28   \n",
       "3           3     Marty Conlon               BOS  29.0         210.82   \n",
       "4           4  Martin Muursepp               DAL  22.0         205.74   \n",
       "\n",
       "   player_weight                    college country draft_year draft_round  \\\n",
       "0      106.59412                Connecticut     USA       1996           1   \n",
       "1      106.59412  North Carolina-Wilmington     USA       1992           2   \n",
       "2      106.59412                       Iowa     USA  Undrafted   Undrafted   \n",
       "3      111.13004                 Providence     USA  Undrafted   Undrafted   \n",
       "4      106.59412                       None     USA       1996           1   \n",
       "\n",
       "  draft_number  gp  pts  reb  ast  net_rating  oreb_pct  dreb_pct  usg_pct  \\\n",
       "0           29  71  4.8  4.5  0.5         6.2     0.127     0.182    0.142   \n",
       "1           50   6  0.3  0.8  0.0       -15.1     0.143     0.267    0.265   \n",
       "2    Undrafted  71  4.5  1.6  0.9         0.9     0.016     0.115    0.151   \n",
       "3    Undrafted  74  7.8  4.4  1.4        -9.0     0.083     0.152    0.167   \n",
       "4           25  42  3.7  1.6  0.5       -14.5     0.109     0.118    0.233   \n",
       "\n",
       "   ts_pct  ast_pct   season  \n",
       "0   0.536    0.052  1996-97  \n",
       "1   0.333    0.000  1996-97  \n",
       "2   0.535    0.099  1996-97  \n",
       "3   0.542    0.101  1996-97  \n",
       "4   0.482    0.114  1996-97  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I typically like to get a feel for the dimensions of the dataset after visualising the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe contains 11700 rows and 22 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataframe contains {df.shape[0]} rows and {df.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be achieved without calling an index, returning a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11700, 22)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now normally like to develop a quick TLDR of my dataset with some summary statistics. This is extremely easy using the \".describe()\" methods of the Pandas class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>player_height</th>\n",
       "      <th>player_weight</th>\n",
       "      <th>gp</th>\n",
       "      <th>pts</th>\n",
       "      <th>reb</th>\n",
       "      <th>ast</th>\n",
       "      <th>net_rating</th>\n",
       "      <th>oreb_pct</th>\n",
       "      <th>dreb_pct</th>\n",
       "      <th>usg_pct</th>\n",
       "      <th>ts_pct</th>\n",
       "      <th>ast_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11700.000000</td>\n",
       "      <td>11700.000000</td>\n",
       "      <td>11700.000000</td>\n",
       "      <td>11700.000000</td>\n",
       "      <td>11700.000000</td>\n",
       "      <td>11700.000000</td>\n",
       "      <td>11700.000000</td>\n",
       "      <td>11700.000000</td>\n",
       "      <td>11700.000000</td>\n",
       "      <td>11700.000000</td>\n",
       "      <td>11700.000000</td>\n",
       "      <td>11700.000000</td>\n",
       "      <td>11700.000000</td>\n",
       "      <td>11700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5849.500000</td>\n",
       "      <td>27.131966</td>\n",
       "      <td>200.728501</td>\n",
       "      <td>100.526791</td>\n",
       "      <td>51.717179</td>\n",
       "      <td>8.169299</td>\n",
       "      <td>3.564957</td>\n",
       "      <td>1.811179</td>\n",
       "      <td>-2.166410</td>\n",
       "      <td>0.054981</td>\n",
       "      <td>0.141534</td>\n",
       "      <td>0.185380</td>\n",
       "      <td>0.510402</td>\n",
       "      <td>0.131228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3377.643409</td>\n",
       "      <td>4.340006</td>\n",
       "      <td>9.169827</td>\n",
       "      <td>12.526481</td>\n",
       "      <td>24.985236</td>\n",
       "      <td>5.956115</td>\n",
       "      <td>2.487498</td>\n",
       "      <td>1.792117</td>\n",
       "      <td>12.076914</td>\n",
       "      <td>0.043595</td>\n",
       "      <td>0.062793</td>\n",
       "      <td>0.052957</td>\n",
       "      <td>0.098306</td>\n",
       "      <td>0.094244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>160.020000</td>\n",
       "      <td>60.327736</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2924.750000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>193.040000</td>\n",
       "      <td>90.718400</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-6.300000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.479000</td>\n",
       "      <td>0.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5849.500000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>200.660000</td>\n",
       "      <td>99.790240</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>-1.300000</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>0.523000</td>\n",
       "      <td>0.103000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8774.250000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>208.280000</td>\n",
       "      <td>108.862080</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.559000</td>\n",
       "      <td>0.178000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11699.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>231.140000</td>\n",
       "      <td>163.293120</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>36.100000</td>\n",
       "      <td>16.300000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0           age  player_height  player_weight            gp  \\\n",
       "count  11700.000000  11700.000000   11700.000000   11700.000000  11700.000000   \n",
       "mean    5849.500000     27.131966     200.728501     100.526791     51.717179   \n",
       "std     3377.643409      4.340006       9.169827      12.526481     24.985236   \n",
       "min        0.000000     18.000000     160.020000      60.327736      1.000000   \n",
       "25%     2924.750000     24.000000     193.040000      90.718400     32.000000   \n",
       "50%     5849.500000     26.000000     200.660000      99.790240     58.000000   \n",
       "75%     8774.250000     30.000000     208.280000     108.862080     74.000000   \n",
       "max    11699.000000     44.000000     231.140000     163.293120     85.000000   \n",
       "\n",
       "                pts           reb           ast    net_rating      oreb_pct  \\\n",
       "count  11700.000000  11700.000000  11700.000000  11700.000000  11700.000000   \n",
       "mean       8.169299      3.564957      1.811179     -2.166410      0.054981   \n",
       "std        5.956115      2.487498      1.792117     12.076914      0.043595   \n",
       "min        0.000000      0.000000      0.000000   -200.000000      0.000000   \n",
       "25%        3.600000      1.800000      0.600000     -6.300000      0.021000   \n",
       "50%        6.700000      3.000000      1.200000     -1.300000      0.042000   \n",
       "75%       11.500000      4.700000      2.400000      3.200000      0.084000   \n",
       "max       36.100000     16.300000     11.700000    300.000000      1.000000   \n",
       "\n",
       "           dreb_pct       usg_pct        ts_pct       ast_pct  \n",
       "count  11700.000000  11700.000000  11700.000000  11700.000000  \n",
       "mean       0.141534      0.185380      0.510402      0.131228  \n",
       "std        0.062793      0.052957      0.098306      0.094244  \n",
       "min        0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.096000      0.150000      0.479000      0.065000  \n",
       "50%        0.132000      0.182000      0.523000      0.103000  \n",
       "75%        0.180000      0.218000      0.559000      0.178000  \n",
       "max        1.000000      1.000000      1.500000      1.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averaging 36.1 points in a season is rpetty unheard of. I know who it was, but for all the viewers at home lets bring up this record using two more Pandas methods in one line of code. First we filter the dataframe to using \".iloc()\" (integer location) and then call the \".idxmax()\" method the return the max value in the specified column. \n",
    "\n",
    "The result is the row/record where this value lies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                   10507\n",
       "player_name           James Harden\n",
       "team_abbreviation              HOU\n",
       "age                           29.0\n",
       "player_height               195.58\n",
       "player_weight             99.79024\n",
       "college              Arizona State\n",
       "country                        USA\n",
       "draft_year                    2009\n",
       "draft_round                      1\n",
       "draft_number                     3\n",
       "gp                              78\n",
       "pts                           36.1\n",
       "reb                            6.6\n",
       "ast                            7.5\n",
       "net_rating                     6.3\n",
       "oreb_pct                     0.023\n",
       "dreb_pct                     0.157\n",
       "usg_pct                      0.396\n",
       "ts_pct                       0.616\n",
       "ast_pct                      0.394\n",
       "season                     2018-19\n",
       "Name: 10507, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[df['pts'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now finish off the data quality checks before diving into the proper EDA using various techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           0\n",
       "player_name          0\n",
       "team_abbreviation    0\n",
       "age                  0\n",
       "player_height        0\n",
       "player_weight        0\n",
       "college              0\n",
       "country              0\n",
       "draft_year           0\n",
       "draft_round          0\n",
       "draft_number         0\n",
       "gp                   0\n",
       "pts                  0\n",
       "reb                  0\n",
       "ast                  0\n",
       "net_rating           0\n",
       "oreb_pct             0\n",
       "dreb_pct             0\n",
       "usg_pct              0\n",
       "ts_pct               0\n",
       "ast_pct              0\n",
       "season               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if there are any numm values in each servies/columns and then summing all nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now the fun begins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've crossed our T's and dotted our I's to ensure our data is of high quality and we don't have to do any data preprocessing and cleaning, let's go over some EDA techniques to get a better feel for the characteristics of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimates of Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean:** The sum of all values divided by the number of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5649572649572736"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With methods\n",
    "df['reb'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5649572649572736"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without methods\n",
    "def my_list(x):\n",
    "    n_students = len(x)\n",
    "    sentinel = 0\n",
    "    total = 0\n",
    "    \n",
    "    while sentinel < n_students:\n",
    "        age = x[sentinel]\n",
    "        total += age\n",
    "        sentinel += 1\n",
    "    mean = total / n_students\n",
    "    return mean\n",
    "\n",
    "my_list(df['reb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trimmed Mean**: Involves removing a user-specified fixed set of numbers from the tails of a distribution and taking the mean from the remaining array.\n",
    "\n",
    "This techniques helps reduce the impact of outliers and is widely preferred to the standard mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without any trim: 3.564957264957265\n",
      "With 1% trim on each end: 3.5056514913657773\n",
      "With 5% trim on each end: 3.3610161443494775\n",
      "With 20% trim on each end: 3.1016381766381764\n"
     ]
    }
   ],
   "source": [
    "# With methods\n",
    "from scipy.stats import trim_mean\n",
    "\n",
    "print(f'Without any trim: {trim_mean(df[\"reb\"], 0)}')\n",
    "print(f'With 1% trim on each end: {trim_mean(df[\"reb\"], 0.01)}')\n",
    "print(f'With 5% trim on each end: {trim_mean(df[\"reb\"], 0.05)}')\n",
    "print(f'With 20% trim on each end: {trim_mean(df[\"reb\"], .2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weighted Mean:** Same as mean but with every value multiplied with a user specified $  X_{i} $ before summing and dividng by the number of values.\n",
    "\n",
    "This techniques is useful when some values are intrinsically more valuable than others or the data collected does not equally represent the different groups we are measuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using points series as weighting: 4.694401595299475\n"
     ]
    }
   ],
   "source": [
    "print(f'Using points as weighting: {np.average(df[\"reb\"], weights = df[\"pts\"])}')\n",
    "print(f'Using points as weighting: {np.average(df[\"reb\"], weights = df[\"pts\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ca4f5ced8312db428f8dd2776d06a9927b3825ff64b08562bfd57df0ffaea7bf"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
